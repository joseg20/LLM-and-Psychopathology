{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16096/3336268860.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jose/Git/SE-AP/experiments/experiment_2/notebooks\n",
      "/home/jose/Git/SE-AP\n",
      "['models', 'todo.md', '.pre-commit-config.yaml', 'demos', '.gitignore', 'experiments', 'include', '.git', '.env', 'README.md', '.env-example', 'LICENSE', 'model_technique_pathology_scores.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Current work\n",
    "print(os.getcwd())\n",
    "# Change directory 2 level up\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "\n",
    "print(os.getcwd())\n",
    "# Look for the file in the directory\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemma\"\n",
    "prompt_technique = \"react\"\n",
    "temperature = 0.9\n",
    "data = pd.read_csv(f\"experiments/experiment_2/results/{model}/results_{prompt_technique}_{model}_{temperature}_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_rows': 159999, 'all_groups_have_160_unique_words': False, 'groups_with_incorrect_word_counts': [{'Induced Pathology': 'Alcohol Addiction', 'Iteration': 54.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Alcohol Addiction', 'Iteration': 59.0, 'Unique Words Count': 158}, {'Induced Pathology': 'Alcohol Addiction', 'Iteration': 86.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Apathy', 'Iteration': 6.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Apathy', 'Iteration': 38.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Apathy', 'Iteration': 63.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Apathy', 'Iteration': 87.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Depression', 'Iteration': 87.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Depression', 'Iteration': 88.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Impulsivity', 'Iteration': 79.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Social Anxiety', 'Iteration': 88.0, 'Unique Words Count': 159}, {'Induced Pathology': 'Trait Anxiety', 'Iteration': 51.0, 'Unique Words Count': 159}], 'incorrect_group_words': {('Alcohol Addiction', 54.0): [], ('Alcohol Addiction', 59.0): [], ('Alcohol Addiction', 86.0): [], ('Apathy', 6.0): [], ('Apathy', 38.0): [], ('Apathy', 63.0): [], ('Apathy', 87.0): [], ('Depression', 87.0): [], ('Depression', 88.0): [], ('Impulsivity', 79.0): [], ('Social Anxiety', 88.0): [], ('Trait Anxiety', 51.0): []}}\n"
     ]
    }
   ],
   "source": [
    "grouped_data = data.groupby(['Induced Pathology', 'Iteration'])\n",
    "\n",
    "unique_words_count = grouped_data['Surveyed Word'].nunique().reset_index(name='Unique Words Count')\n",
    "\n",
    "total_rows = len(data)\n",
    "\n",
    "expected_words_per_group = 160\n",
    "\n",
    "valid_groups = unique_words_count['Unique Words Count'] == expected_words_per_group\n",
    "\n",
    "all_groups_valid = valid_groups.all()\n",
    "\n",
    "incorrect_groups = unique_words_count[~valid_groups]\n",
    "\n",
    "incorrect_group_words = {}\n",
    "for _, row in incorrect_groups.iterrows():\n",
    "    pathology = row['Induced Pathology']\n",
    "    iteration = row['Iteration']\n",
    "    group_data = data[(data['Induced Pathology'] == pathology) & (data['Iteration'] == iteration)]\n",
    "    duplicate_words = group_data[group_data.duplicated(subset=['Surveyed Word'], keep=False)]['Surveyed Word'].unique()\n",
    "    incorrect_group_words[(pathology, iteration)] = list(duplicate_words)\n",
    "    \n",
    "result = {\n",
    "    \"total_rows\": total_rows,\n",
    "    \"all_groups_have_160_unique_words\": all_groups_valid,\n",
    "    \"groups_with_incorrect_word_counts\": incorrect_groups.to_dict(orient='records'),\n",
    "    \"incorrect_group_words\": incorrect_group_words\n",
    "}\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_categories_have_80_unique_words': False,\n",
       " 'groups_with_incorrect_word_counts':       Induced Pathology  Iteration  Category  Unique Words Count\n",
       " 107   Alcohol Addiction       54.0  Concrete                  79\n",
       " 116   Alcohol Addiction       59.0  Abstract                  79\n",
       " 117   Alcohol Addiction       59.0  Concrete                  79\n",
       " 170   Alcohol Addiction       86.0  Abstract                  79\n",
       " 210              Apathy        6.0  Abstract                  79\n",
       " 274              Apathy       38.0  Abstract                  79\n",
       " 325              Apathy       63.0  Concrete                  79\n",
       " 326              Apathy       63.0   Unknown                   0\n",
       " 373              Apathy       87.0  Abstract                  79\n",
       " 573          Depression       87.0  Abstract                  79\n",
       " 575          Depression       88.0  Abstract                  79\n",
       " 958         Impulsivity       79.0  Concrete                  79\n",
       " 959         Impulsivity       79.0   Unknown                   0\n",
       " 1777     Social Anxiety       88.0  Concrete                  79\n",
       " 1902      Trait Anxiety       51.0  Abstract                  79}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_by_category = data.groupby(['Induced Pathology', 'Iteration', 'Category'])\n",
    "unique_words_per_category = grouped_by_category['Surveyed Word'].nunique().reset_index(name='Unique Words Count')\n",
    "\n",
    "expected_words_per_category = 80\n",
    "category_word_counts_valid = unique_words_per_category['Unique Words Count'] == expected_words_per_category\n",
    "\n",
    "groups_with_incorrect_word_counts = unique_words_per_category[~category_word_counts_valid] if not category_word_counts_valid.all() else None\n",
    "\n",
    "{\n",
    "    \"all_categories_have_80_unique_words\": category_word_counts_valid.all(),\n",
    "    \"groups_with_incorrect_word_counts\": groups_with_incorrect_word_counts\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concreteness = pd.read_json('experiments/experiment_2/data/concreteness.json')\n",
    "\n",
    "missing_words_per_iteration = {}\n",
    "\n",
    "for (pathology, iteration, category), df_group in data.groupby(['Induced Pathology', 'Iteration', 'Category']):\n",
    "    key = f\"{pathology} | Iteration: {iteration} | {category}\"\n",
    "    expected_words = concreteness.get(category, [])\n",
    "    present_words = df_group['Surveyed Word'].unique()\n",
    "    missing_words = [word for word in expected_words if word not in present_words]\n",
    "    \n",
    "    if missing_words:\n",
    "        missing_words_per_iteration[key] = missing_words\n",
    "\n",
    "list(missing_words_per_iteration.items())[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psy_inv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
